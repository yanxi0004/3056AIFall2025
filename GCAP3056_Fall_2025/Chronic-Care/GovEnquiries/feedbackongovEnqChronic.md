# Feedback on Government Enquiries - Chronic Disease Co-Care Pilot Scheme

## Conversation Summary

This document captures the key lessons learned from reviewing and revising government information requests for the Chronic Disease Co-Care (CDCC) Pilot Scheme research project.

## Key Lessons for Writing Government Enquiries

### 1. **Request Data, Not Analyses**
**Problem**: Original questions asked for analyses that government departments likely don't have prepared.
**Solution**: Focus on requesting factual data, statistics, and raw information that can be used for our own analysis.

**Examples of Poor Requests:**
- "Analysis of CDCC's integration with public healthcare services"
- "Impact of CDCC on public healthcare utilization patterns"
- "Analysis of factors associated with successful treatment continuation"

**Examples of Good Requests:**
- "Number of CDCC participants who also use public healthcare services"
- "Monthly appointment numbers for CDCC participants at public healthcare facilities"
- "Number of participants who continue treatment at 3 months, 6 months, 12 months"

### 2. **Be Specific About What You Need**
**Problem**: Vague requests like "promotion effectiveness analysis" are too broad.
**Solution**: Request specific numbers, lists, and statistics.

**Good Examples: "Total expenditure on promotion and awareness campaigns since program launch (by year and quarter)"

### 3. **Include Alternative Plans**
**Problem**: No backup strategy when government data isn't available.
**Solution**: Always include alternative data sources and research strategies.

**Example Alternative Plans:**
- Research international programs for benchmarking
- Use publicly available government press releases
- Conduct academic research on international best practices
- Use existing research on chronic disease management

### 4. **Target Appropriate Government Departments**
**Problem**: Sending all requests to one department.
**Solution**: Match information needs with department expertise.

**Department Mapping:**
- **Department of Health**: Program data, health outcomes, participation statistics
- **Health Bureau**: Policy direction, budget allocation, future plans
- **Census and Statistics Department**: Population health statistics, demographics
- **Hospital Authority**: Public healthcare integration, service capacity

### 5. **Provide Context for Each Request**
**Problem**: Requests without context may be ignored or misunderstood.
**Solution**: Explain why the information is needed and how it will be used.

**Example Context:**
"Context: Our research shows the scheme has enrolled 131,200 participants with 74,900 completing screening. To evaluate cost-effectiveness against international benchmarks (like Singapore's Screen for Life program), we need comprehensive financial data."

### 6. **Limit Questions Per Request**
**Problem**: Too many questions in one request may overwhelm departments.
**Solution**: Maximum 3 focused questions per request, with clear purpose.

### 7. **Use Academic Research Framework**
**Problem**: Requests that don't align with academic research standards.
**Solution**: Frame requests within academic research context with clear methodology.

**Example Framework:**
- Academic research purpose
- Specific research questions
- How data will support argument development
- Alternative research strategies

### 8. **Plan for Data Limitations**
**Problem**: Assuming all requested data will be available.
**Solution**: Develop comprehensive contingency plans using multiple data sources.

**Contingency Strategies:**
- International benchmarking using academic sources
- Public information analysis
- Comparative research with similar programs
- Economic and policy analysis using available data

## Revised Question Structure

### Effective Question Template:
```
### Question X: [Specific Topic]
**Context**: [Why this information is needed for research]
**Request**: Please provide:
1. [Specific data point 1]
2. [Specific data point 2] 
3. [Specific data point 3]
**Argument Development**: [How this data will support research arguments]
**Alternative Plan**: [What to do if data is not available]
```

## Implementation Strategy

### Timeline:
- **Week 1-2**: Submit information requests to respective departments
- **Week 3-4**: Follow up on requests and clarify any questions
- **Week 5-6**: Analyze received information and identify additional data needs
- **Week 7-8**: Integrate findings into ARP development

### Success Metrics:
- **Response rate**: Target 80% of requests answered within 30 days
- **Data quality**: Comprehensive, current, and actionable information
- **Argument strength**: Information directly supports evidence-based recommendations
- **Policy alignment**: Recommendations align with government priorities and capabilities

## Key Takeaways

1. **Government departments have data, not analyses** - Request raw information for your own analysis
2. **Be specific and focused** - Vague requests get vague responses
3. **Always have a backup plan** - Government data may not be available or complete
4. **Target the right department** - Match information needs with department expertise
5. **Provide clear context** - Explain why you need the information and how you'll use it
6. **Plan for limitations** - Develop alternative research strategies
7. **Use academic framework** - Frame requests within proper research methodology
8. **Be realistic** - Focus on information that departments likely have available

## Final Recommendations

The revised government enquiries now focus on:
- **Factual data and statistics** rather than analyses
- **Specific, actionable requests** rather than broad questions
- **Alternative research strategies** when government data is limited
- **Appropriate department targeting** based on information needs
- **Clear academic research context** for all requests

This approach significantly increases the likelihood of receiving useful responses while maintaining research rigor and policy relevance.
